# %%
import numpy as np

# %%
a = [1,2,3,4] 
print(a)
b = np.array(a)
b

# %%
#创建数组，指定数据类型
a = np.array([1,2,3],float) 
a

# %%
#创建多维数组
a2 = np.array([(1,2,3),(4,5,6),(7,8,9),(10,11,12)],dtype=float)
print(a2)
a2.shape  

# %%
#numpy创建特殊数组
#创建两个2行3列,全为0的数组
a3 = np.zeros((2,2,3),dtype=int)
a3

# %%

#创建全为1的数组
a4 = np.ones((3,3))
a4

# %%
#创建等差数列，
a5 = np.arange(1,10,0.6)
a5

# %%
#创建对角线1的数组，降维
a6 = np.eye(4)
print(a6)
a6.reshape(16)

# %%
#[0,1))之间平均分布的随机数组,指定长度
np.random.random(5)


# %%
#生成指定长度，符合正态分布的随机数组
mu,sigma =1,0.2
np.random.normal(mu,sigma,5)

# %%
#numpy数组的访问,支持切片每个维度
a7 = np.array([(1,2,3),(4,5,6),(7,8,9),(10,11,12)])
print(a7[0])#输出第0个
print()
print(a7[1:])#输出从第1到最后（包含1）
print()
print(a7[:2]) #输出第2到开始（不包含2）
print()
print(a7[1: , 1:])  #输出第1到最后,第1到最后
print()
a7[1][2]#输出第1个，第2个值

# %%
#numpy数组遍历
a8 = np.array([1,2,3])
for i in a8:
    print(i)

# %%
#多维数组遍历
a9 = np.array([(1,2,3),(4,5,6),(7,8,9)])
for i,o,p in a9:
    print(i*o*p)

# %%
#数组常用属性

b1 = np.array([(1,2,3),(4,5,6),(7,8,9)],dtype=float)
#数组的维度（数组轴的个数），等于秩
print('ndim',b1.ndim)
# 数组的⼤⼩。为⼀个表⽰数组在每个维度上⼤⼩的整数元组。例如⼆维数组中，表⽰数组的’ ⾏数’ 和’ 列数”
print('shape',b1.shape)
#数组元素的总个数，等于 shape 属性中元组元素的乘积
print('size',b1.size)
#表⽰数组中元素类型的对象
print('dtype',b1.dtype)

# %%
#numpy数组的基本操作
#检测数值是否在数组中
b2 = np.array([(1,2,3),(4,5,6)])
print(2 in b2)
print(9 in b2)

# %%
#数组的重排列，例如将⼀个 3 维数组转变为 1 维（元素数⼀定要保持不变）
b3 = np.array([(1,2,3),(4,5,6),(7,8,9)])
print(b3)
b3.reshape(9)
print()
print(b3.reshape(9))
print()
b3.transpose()#转置
print(b3.transpose())
b3.T

# %%
#把多维数组转换为⼀维数组，注意每个元组的⻓度是相同的
b4 = np.array([(1,2,3),(4,5,6),(7,8,9)])
print(b4)
b4.flatten()

# %%
#增加维度
b5 = np.array([2,3,4,5])
b5.shape

# %%
b5 = b5[:,np.newaxis]
b5
b5.shape

# %%
#NumPy 数组的数学操作
#加减乘除
q=np.ones([2,2])
w=np.array([(-1,1),(-1,1)])
print(q)
print(w)
print()
q+w
print(q+w)
print()
q-w
print(q-w)
print()
q*w
print(q*w)
print()
q/w
print(q/w)

# %%
#求和、求积
s1 = np.array([1,2,3,4])
print(s1.sum())

s1.prod()


# %%
#平均数，⽅差，标准差，最⼤值，最⼩值
s2 = np.array([9,6,5,1])
print("mean:",s2.mean())
print("var:", s2.var())
print("std:", s2.std())
print("max:", s2.max())
print("min:", s2.min())

# %%
#最⼤与最⼩值对应的索引值：argmax,argmin:
#取元素值上限，下限，四舍五⼊：ceil, floor, rint
s3 = np.array([2.4, 4.8, 9.9])
print("argmax:", s3.argmax())
print("argmin:", s3.argmin())
print("ceil:", np.ceil(s3))
print("floor:", np.floor(s3))
print("rint:", np.rint(s3))

# %%
#升序
s4 = np.array([14,10,17,1.3,11,15,13.2])
s4.sort()
s4

# %%
import numpy as np
# 定义两个简单的矩阵
m1 = np.array([(1, 2), (3, 4)], dtype=np.float32)
m2 = np.array([(5, 6), (7, 8)], dtype=np.float32)
              
# 使⽤ np.dot 进⾏矩阵乘法
result_dot = np.dot(m1, m2)

# 使⽤ @ 运算符进⾏矩阵乘法
result_at = m1 @ m2

print("矩阵 1:")
print(m1)
print("矩阵 2:")
print(m2)
print("使⽤ np.dot 得到的矩阵乘法结果:")
print(result_dot)
print("使⽤ @ 运算符得到的矩阵乘法结果:")
print(result_at)
print("使⽤ @ 运算符得到的矩阵乘法结果:")
print(result_at)
# 创建⼀个全零矩阵，⽤于存储⼿动推演的结果
# 结果矩阵的⾏数等于 matrix1 的⾏数，列数等于 matrix2 的列数
manual_result = np.zeros((m1.shape[0], m2.shape[1]), dtype=np.float32)
# 外层循环：遍历 matrix1 的每⼀⾏
# i 表⽰结果矩阵的⾏索引
for i in range(m1.shape[0]):
    # 中层循环：遍历 matrix2 的每⼀列
    # j 表⽰结果矩阵的列索引
    for j in range(m2.shape[1]):
        # 初始化当前位置的结果为 0
        manual_result[i, j] = 0
        # 内层循环：计算 matrix1 的第 i ⾏与 matrix2 的第 j 列对应元素的乘积之和
        # k 表⽰参与乘法运算的元素索引
        for k in range(m1.shape[1]):
            # 打印当前正在计算的元素
            print(f"{m1[i, k]} * {m2[k, j]} = {m1[i, k] * m2[k, j]}")
             # 将 matrix1 的第 i ⾏第 k 列元素与 matrix2 的第 k ⾏第 j 列元素相乘，并累
            manual_result[i, j] += m1[i, k] * m2[k, j]
        # 打印当前位置计算完成后的结果
        print(f"结果矩阵[{i+1},{j+1}]:{manual_result[i, j]}\n")
            
print("⼿动推演结果:")
print(manual_result)

# %%
#⽂件操作
np.save ('123.npy',manual_result)


# %%
np.load ('123.npy')

# %%
#NumPy ⼴播机制
a = np.array([1,2,3])
b = np.array([4,5,6])
a + b

# %%
a = np.array([(1,1), (2,2), (3,3), (4,4)])
print(a.shape)
b = np.array([3,3])#4个[3,3]
print(b.shape)
a * b

# %%
#pytorch 张量
import torch

data =([1,2],[3,4]) 

torch.tensor(data)

# %%
import numpy as np
np_array1 = np.array([(1,2,3),(4,5,6)])

data1 =torch.from_numpy(np_array1)
data1

# %%
#参照已知张量,创建新的
data2=torch.ones_like(data1)
print(data2)
data2=torch.zeros_like(data1)
print(data2)
data2=torch.rand_like(data1,dtype=torch.float32)#创建随机数时候指定张量类型
print(data2)

# %%
#使用随机值或常量值
shape = (4,5)
rand_tensor = torch.rand(shape)
ones_tensor = torch.ones(shape)
zeros_tensor = torch.zeros(shape)
print(f"Random Tensor: \n {rand_tensor} \n")
print(f"Ones Tensor: \n {ones_tensor} \n")
print(f"Zeros Tensor: \n {zeros_tensor}")

# %%
# 基于现有tensor构建，但使⽤新值填充
m = torch.ones(5,3, dtype=torch.double)#双精度
n = torch.rand_like(m, dtype=torch.float)
# 获取tensor的⼤⼩
print(m.size()) # torch.Size([5,3])
# 均匀分布
print(torch.rand(5,3))
# 标准正态分布
print(torch.randn(5,3))
# 离散正态分布
print(torch.normal(mean=.0,std=1.0,size=(5,3)))
# 线性间隔向量(返回⼀个1维张量，包含在区间start和end上均匀间隔的steps个点
print(torch.linspace(start=1,end=5,steps=12))

# %%
tensor = torch.rand([2,3],dtype=torch.float64)
print(f"Shape of tensor: {tensor.shape}")
print(f"Datatype of tensor: {tensor.dtype}")
print(f"Device tensor is stored on: {tensor.device}")#创建在内存中

# %%
# 设置张量在GPU上运算
if torch.cuda.is_available():#需要cuda环境
    device = torch.device('cuda')#GPU不行= =
    tensor = tensor.to(device)
print(tensor)
print(tensor.device)

#M系列芯片
if torch.backends.mps.is_available():
    device = torch.device('mps')#GPU不行= =
    tensor = tensor.to(device)
print(tensor)
print(tensor.device)


# %%

data4 =torch.arange(1,17,).reshape(4,4)   #([(1,2,3,4),(5,6,7,8),(9,10,11,12),(13,14,15,16)]) 
tensor = torch.tensor(data4)
print('First row: ', tensor[0])#第一行
print('First column: ', tensor[:, 0])#所有行第一列
print('Last column:', tensor[..., -1])#所有行的最后一列
tensor[:,1] = 0 #第一列都为0
print(tensor)

# %%
#使⽤ torch.cat ⽤来连接指定维度的⼀系列张量
t1 = torch.cat([tensor, tensor, tensor], dim=1)#
print(t1)
print(t1.shape)
print()
#使⽤ torch.stack ⽤来连接指定维度的⼀系列张量
t1 = torch.stack([tensor, tensor, tensor], dim=0)#
print(t1)
print(t1.shape)


# %%
# 计算两个张量之间矩阵乘法的⼏种⽅式。 y1, y2, y3 最后的值是⼀样的 dot
tensor=torch.arange(1,10,dtype=torch.float32).reshape(3,3)
y1 = tensor @ tensor.T
y2 = tensor.matmul(tensor.T)
print(y1)
print(y2)
y3 = torch.rand_like(tensor)
torch.matmul(tensor, tensor.T, out=y3)
print(y3)
# 计算张量逐元素相乘的⼏种⽅法。 z1, z2, z3 最后的值是⼀样的。
z1 = tensor * tensor
z2 = tensor.mul(tensor)
print(z1)
print(z2)
z3 = torch.rand_like(tensor)
torch.mul(tensor, tensor, out=z3)

# %%
#如果⼀个单元素张量，例如将张量的值聚合计算，可以使⽤ item() ⽅法将其转换为Python 数值
tensor2 = torch.arange(1,16,dtype=torch.float32).reshape(3,5)
print(tensor2)
agg = tensor2.sum()
agg_item = agg.item()
print(agg_item, type(agg_item))

# %%
#in_place
#张量内部的值，直接被修改
print(tensor2,'\n')
tensor2.add_(10)
print(tensor2)

# %%
from torchviz import make_dot
# 定义矩阵 A，向量 b 和常数 c
A = torch.randn(10, 10,requires_grad=True)
b = torch.randn(10,requires_grad=True)
c = torch.randn(1,requires_grad=True)
x = torch.randn(10, requires_grad=True)
# 计算 x^T * A + b * x + c 
result = torch.matmul(A, x.T) + torch.matmul(b, x) + c
# ⽣成计算图节点
dot = make_dot(result, params={'A': A, 'b': b, 'c': c, 'x': x})
# 绘制计算图
dot.render('expression', format='png', cleanup=True, view=False)


