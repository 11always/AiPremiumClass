{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一 张量的创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[16, 12],\n",
      "        [ 4,  6]])\n",
      "tensor([[16, 27, 12],\n",
      "        [ 4,  5,  6],\n",
      "        [ 7,  8,  9]], dtype=torch.int32)\n",
      "ones tensor: \n",
      " tensor([[1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 1]], dtype=torch.int32)\n",
      "\n",
      "random tensor: \n",
      " tensor([[0.9223, 0.0058],\n",
      "        [0.2308, 0.7205]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "#张量直接从数据中创建\n",
    "a = [[16,12],[4,6]]\n",
    "ts1 = torch.tensor(a)\n",
    "print(ts1)\n",
    "\n",
    "#  张量从numpy数组中创建 \n",
    "b = np.array([[16,27,12],[4,5,6],[7,8,9]])\n",
    "ts2 = torch.from_numpy(b)\n",
    "print(ts2)\n",
    "\n",
    "#张量从另外一个张量创建,保留of x_data的属性\n",
    "ts3 = torch.ones_like(ts2)\n",
    "print(f\"ones tensor: \\n {ts3}\\n\")\n",
    "\n",
    "#张量从另外一个张量创建,覆盖 x_data的属性\n",
    "ts4 = torch.rand_like(ts1, dtype=torch.float)\n",
    "print(f\"random tensor: \\n {ts4}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.3233, 0.4934, 0.2579, 0.2368, 0.6110],\n",
      "        [0.4387, 0.4332, 0.3634, 0.3094, 0.2486],\n",
      "        [0.3811, 0.7582, 0.5013, 0.2447, 0.8084],\n",
      "        [0.9252, 0.4102, 0.4594, 0.2842, 0.7794]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "#随机值创建张量\n",
    "shape =(4,5)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000,  1.4737,  1.9474,  2.4211,  2.8947,  3.3684,  3.8421,  4.3158,\n",
       "         4.7895,  5.2632,  5.7368,  6.2105,  6.6842,  7.1579,  7.6316,  8.1053,\n",
       "         8.5789,  9.0526,  9.5263, 10.0000])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 基于现有tensor构建，但使⽤新值填充\n",
    "m = torch.ones(5,3, dtype=torch.double)\n",
    "n = torch.rand_like(m, dtype=torch.float)\n",
    "# 获取tensor的⼤⼩\n",
    "print(m.size()) # torch.Size([5,3])\n",
    "# 均匀分布\n",
    "torch.rand(5,3)\n",
    "# 标准正态分布\n",
    "torch.randn(5,3)\n",
    "# 离散正态分布\n",
    "torch.normal(mean=.0,std=1.0,size=(5,3))\n",
    "# 线性间隔向量(返回⼀个1维张量，包含在区间start和end上均匀间隔的steps个点)\n",
    "torch.linspace(start=1,end=10,steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor shape: torch.Size([2, 2])\n",
      "tensor dtype: torch.int64\n",
      "tensor device: cpu\n"
     ]
    }
   ],
   "source": [
    "#张量的属性\n",
    "print(f\"tensor shape: {ts1.shape}\")\n",
    "print(f\"tensor dtype: {ts1.dtype}\")\n",
    "print(f\"tensor device: {ts1.device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "二 张量运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 设置张量在GPU上运算\n",
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(34)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#张量的索引和切⽚：\n",
    "ts5 = torch.tensor([[1,7,3],[8,5,34],[7,34,339]])\n",
    "# ts2[0]  展示第⼀⾏tensor([1, 7, 3])\n",
    "# ts5[0:2]  # 展示前两⾏  \n",
    "# ts5[0:2,1]  # 展示前两⾏的第⼆列tensor([7, 5])\n",
    "\n",
    "\n",
    "# ts2[0,2]  第⼀⾏第三列   tensor(3)\n",
    "# ts5[:,0]  # 展示第⼀列 tensor([1, 8, 7])\n",
    "# ts5[...,0]  # 第⼀列\n",
    "ts5[1,2]   # 第⼆⾏第三列\n",
    "# ts5[1,2] = 100  # 修改张量的值\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1,   7,   3,   1,   7,   3,   1,   1,   1],\n",
       "        [  8,   5,  34,   8,   5,  34,   1,   1,   1],\n",
       "        [  7,  34, 339,   7,  34, 339,   1,   1,   1]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#张量的拼接\n",
    "ts6 = torch.cat([ts5, ts2,ts3], dim=1)\n",
    "ts6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts5 + ts7 = tensor([[ 52,   7,  12],\n",
      "        [  9,   7,  38],\n",
      "        [ 41,  56, 678]])\n",
      "ts5 - ts7 = tensor([[-50,   7,  -6],\n",
      "        [  7,   3,  30],\n",
      "        [-27,  12,   0]])\n",
      "ts5 * ts7 = tensor([[    51,      0,     27],\n",
      "        [     8,     10,    136],\n",
      "        [   238,    748, 114921]])\n",
      "ts5 / ts7 = tensor([[0.0196,    inf, 0.3333],\n",
      "        [8.0000, 2.5000, 8.5000],\n",
      "        [0.2059, 1.5455, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "#算术运算\n",
    "ts5 = torch.tensor([[1,7,3],[8,5,34],[7,34,339]])\n",
    "ts7 = torch.tensor([[51,0,9],[1,2,4],[34,22,339]])\n",
    "# 加法\n",
    "print(f\"ts5 + ts7 = {ts5 + ts7}\")\n",
    "# 减法\n",
    "print(f\"ts5 - ts7 = {ts5 - ts7}\")\n",
    "# 乘法\n",
    "print(f\"ts5 * ts7 = {ts5 * ts7}\")\n",
    "# 除法\n",
    "print(f\"ts5 / ts7 = {ts5 / ts7}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts5 @ ts7 = tensor([[   160,     80,   1054],\n",
      "        [  1569,    758,  11618],\n",
      "        [ 11917,   7526, 115120]])\n",
      "ts5.matmul(ts7) = tensor([[   160,     80,   1054],\n",
      "        [  1569,    758,  11618],\n",
      "        [ 11917,   7526, 115120]])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-3518cdf1dc8e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mts5\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mts7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"ts5.matmul(ts7) = {u}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mts3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mts3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tensor' is not defined"
     ]
    }
   ],
   "source": [
    "ts5 = torch.tensor([[1,7,3],[8,5,34],[7,34,339]])\n",
    "ts7 = torch.tensor([[51,0,9],[1,2,4],[34,22,339]])\n",
    "s =ts5 @ ts7\n",
    "print(f\"ts5 @ ts7 = {s}\")\n",
    "u = ts5.matmul(ts7)\n",
    "print(f\"ts5.matmul(ts7) = {u}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "462 <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "#单元素张量聚合转换数值可以使⽤item()⽅法将其转换为 Python 数值\n",
    "H = ts7.sum()\n",
    "H_item = H.item()\n",
    "print(H_item, type(H_item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 12,  33],\n",
      "        [212,  11]]) \n",
      "\n",
      "tensor([[3244, 3265],\n",
      "        [3444, 3243]])\n"
     ]
    }
   ],
   "source": [
    "#In-place操作把计算结果存储到当前操作数中的操作\n",
    "ts2 =torch.tensor([[12,33],[212,11]])\n",
    "print(ts2, \"\\n\")\n",
    "ts2.add_(3232)\n",
    "print(ts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ts7' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1744\\943806526.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#与numpy之间的转换---张量到numpy数组\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mts7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mnpy1\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mts7\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnpy1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# print(f'npy1:{n}')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ts7' is not defined"
     ]
    }
   ],
   "source": [
    "#与numpy之间的转换---张量到numpy数组\n",
    "print(ts7)\n",
    "npy1 =ts7.numpy()\n",
    "print(npy1)\n",
    "# print(f'npy1:{n}')\n",
    "ts7.add_(2)\n",
    "print(npy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[16, 27, 12],\n",
      "        [ 4,  5,  6],\n",
      "        [ 7,  8,  9]], dtype=torch.int32)\n",
      "[[37 48 33]\n",
      " [25 26 27]\n",
      " [28 29 30]]\n"
     ]
    }
   ],
   "source": [
    "#与numpy之间的转换---Numpy数组到张量\n",
    "b = np.array([[16,27,12],[4,5,6],[7,8,9]])\n",
    "ts2 = torch.from_numpy(b)\n",
    "print(ts2)\n",
    "np.add(b, 21, out=b)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "三 pytorch计算图可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\soft\\anacona-tool\\envs\\py12\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3281.)\n",
      "  if __name__ == \"__main__\":\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'expression.png'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchviz import make_dot\n",
    "# 定义矩阵 A，向量 b 和常数 c\n",
    "A = torch.randn(10, 10,requires_grad=True)\n",
    "b = torch.randn(10,requires_grad=True)\n",
    "c = torch.randn(1,requires_grad=True)\n",
    "x = torch.randn(10, requires_grad=True)\n",
    "# 计算 x^T * A + b * x + c\n",
    "result = torch.matmul(A, x.T) + torch.matmul(b, x) + c\n",
    "# ⽣成计算图节点\n",
    "dot = make_dot(result, params={'A': A, 'b': b, 'c': c, 'x': x})\n",
    "# 绘制计算图\n",
    "dot.render('expression', format='png', cleanup=True, view=False)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
