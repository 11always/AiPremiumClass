{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 4],\n",
      "        [2, 8]])\n",
      "tensor([[1, 4],\n",
      "        [2, 8]], dtype=torch.int32)\n",
      "ones tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]])\n",
      "\n",
      "random tensor: \n",
      " tensor([[0.6037, 0.4700],\n",
      "        [0.8506, 0.3789]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "#张量直接从数据中创建\n",
    "data = [[1,4],[2,8]]\n",
    "x_data = torch.tensor(data)\n",
    "print(x_data)\n",
    "\n",
    "#  张量从numpy数组中创建 \n",
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "print(x_np)\n",
    "\n",
    "#张量从另外一个张量创建,保留of x_data的属性\n",
    "x_data = torch.ones_like(x_data)\n",
    "print(f\"ones tensor: \\n {x_data}\\n\")\n",
    "\n",
    "#张量从另外一个张量创建,覆盖 x_data的属性\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float)\n",
    "print(f\"random tensor: \\n {x_rand}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shape是张量的维度.使用随机值创建张量\n",
    "shape = (2,3,)  #2行3列\n",
    "rand_tensor = torch.rand(shape) #创建一个随机张量   \n",
    "ones_tensor = torch.ones(shape)     #创建一个全是1的张量   \n",
    "zeros_tensor = torch.zeros(shape)   #创建一个全是0的张量    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m: tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "\n",
      "n: tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "\n",
      "torch.Size([5, 3])\n",
      "torch.Size([5, 3])\n",
      "shape of tensor: torch.Size([5, 3])\n",
      "datatype of tensor: torch.float32\n",
      "device of tensor: cpu\n"
     ]
    }
   ],
   "source": [
    "m = torch.ones(5,3,dtype=torch.double)\n",
    "n = torch.ones(5,3,dtype=torch.float)\n",
    "print(f\"m: {m}\\n\")\n",
    "print(f\"n: {n}\\n\")\n",
    "print(m.size())  #获取张量的大小\n",
    "print(m.shape)  #获取张量的形状\n",
    "\n",
    "tensor = torch.rand(5,3)\n",
    "print(f\"shape of tensor: {tensor.shape}\")\n",
    "print(f\"datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"device of tensor: {tensor.device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#设置张量在GPU上运算\n",
    "# if torch.cuda.is_available():\n",
    "#     tensor = tensor.to('cuda')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "first row:  tensor([1., 0., 1., 1.])\n",
      "first column:  tensor([1., 1., 1., 1.])\n",
      "last column:  tensor([1., 1., 1., 1.])\n",
      "last column:  tensor([1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "#张量的索引与切片\n",
    "tensor = torch.ones(4,4)\n",
    "tensor[:,1] = 0   #将第二列的所有元素设置为0\n",
    "print(tensor)\n",
    "\n",
    "print(\"first row: \",tensor[0])  #获取第一行\n",
    "print(\"first column: \",tensor[:,0])  #获取第一列\n",
    "print(\"last column: \",tensor[...,-1])  #获取最后一列\n",
    "print(\"last column: \",tensor[:,-1])  #获取最后一列\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#张量的拼接\n",
    "t1 = torch.cat([tensor,tensor,tensor],dim=1) #在第二维度上拼接\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   1,  169],\n",
      "        [   4, 2025]])\n",
      "tensor([[   1,  169],\n",
      "        [   4, 2025]])\n",
      "tensor([[1.0000e+00, 1.6900e+02],\n",
      "        [4.0000e+00, 2.0250e+03]])\n"
     ]
    }
   ],
   "source": [
    "tensor1 = torch.tensor([[1,13],[2,45]])\n",
    "# print(tensor1)#\n",
    "\n",
    "# y1 = tensor1 @ tensor1.T  #矩阵乘法\n",
    "# y2 = tensor1.matmul(tensor1.T)  #矩阵乘法\n",
    "# y3 = torch.rand_like(tensor1)  #创建一个与tensor相同形状的张量\n",
    "#这里要在后面加上 dtype=torch.float\n",
    "# torch.matmul(tensor1,tensor1.T,out=y3)  #矩阵乘法\n",
    "# print(y1)   \n",
    "# print(y2)  \n",
    "# print(y3)\n",
    "\n",
    "y4 = tensor1 * tensor1  #对应元素相乘\n",
    "print(y4)\n",
    "y5 = tensor1.mul(tensor1)  #对应元素相乘\n",
    "print(y5)\n",
    "y6 = torch.rand_like(tensor1,dtype=torch.float)  #创建一个与tensor相同形状的张量\n",
    "torch.mul(tensor1,tensor1,out=y6)  #对应元素相乘        \n",
    "print(y6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(61)\n",
      "61\n"
     ]
    }
   ],
   "source": [
    "agg = tensor1.sum()  #求和\n",
    "print(agg)\n",
    "agg_item = agg.item()  #将张量的值转换为python数值\n",
    "print(agg_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1, 13],\n",
      "        [ 2, 45]])\n",
      "[[ 1 13]\n",
      " [ 2 45]]\n",
      "tensor([[ 6, 18],\n",
      "        [ 7, 50]])\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(tensor1)\n",
    "print(tensor1.numpy())  #将张量转换为numpy数组 \n",
    "\n",
    "tensor2 =tensor1.add(5)  #加法\n",
    "print(tensor2)\n",
    "\n",
    "#\n",
    "n = np.ones(5)\n",
    "t =torch.from_numpy(n)  #将numpy数组转换为张量\n",
    "print(t)\n",
    "n = t.numpy()  #将张量转换为numpy数组\n",
    "print(n)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "libai",
   "language": "python",
   "name": "xcjpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
