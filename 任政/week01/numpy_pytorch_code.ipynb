import numpy as np
a1 = np.zeros((2,3))    # 创建全零矩阵
a2 = np.ones((5,5))    # 创建全1矩阵
a3 = np.eye(5)          # 创建单位矩阵   关于对角线对称
a3

a4 = np.random.random(10)   # 创建十个0-1中间的数
a5 = np.random.normal(2,3,5)  # 正态分布，2为均值，3为标准差，5是数量
a5

a7 = np.array([(1,5), (3,4), (5,6)])    # 包含元祖的列表
#for i,j in a7:    # 循环输出每一行的数字
    #print(i,j)
a7
a7.ndim   # 查看几维
a7.shape   # 查看形状
a7.size  # 查看变量大小
a7.dtype   # 查看数据类型

5 in a7    # 该数是否在里边

a8 = np.arange(1,10)
a8.shape  # 形状 9个

a8 = a8.reshape(3,3,1)  # 将a8调整成3维数组, 第一个维度为3 第二个维度为3 第三个维度为1
a8

a9 = np.array([(1,2,3), (4,5,6), (7,8,9)])
a9 = a9.T    # a9的转置
a9
# a9 = a9.flatten() # 将多维数组转成一维数组
a9

a9  = a9[np.newaxis]   # 新增一个维度
a9.shape

a10 = np.array([(1,2), (3,4), (5,6)])
a10 = a10 [:  , np.newaxis]  # 在第二位增加维度
a10.shape
#%%
a = np.ones((2,3))
b = np.array([(1,1,1),(1,1,1)])
a+b
a-b
b.sum()
b.prod()   # 计算全部元素的乘积

a = np.array([6,7,8,9,10])
a.mean()  # 求平均值
a.var()  # 计算所有元素的方差 （先求出每个元素与平均值的差值的平方，再求这些平方值的平均值。即 ((6 - 8)² + (7 - 8)² + (8 - 8)² + (9 - 8)² + (10 - 8)²) / 5 = 2.0。)
a.std()   # 计算标准差，是方差的平方根
#%%
import numpy as np
a = np.array([1.02, 3.8, 4.9,5.55,2.33])
a.argmax()  # 获取最大值索引
a.argmin()  # 获取最小值索引

np.ceil(a)   # 所有元素向上取整
np.floor(a)  # 向下取整
np.rint(a)  # 根据四舍五入 取整

a.sort()   # 从小到大排序
a = np.sort(a)[::-1] # 从大到小排序
a

#%%
import torch
import numpy as np
tensor = torch.arange(1 , 17 ).reshape(4,4).to(torch.float32)  # 创建四行四列的张量，范围1-17 17不取
# tensor = tensor.T   # 张量转置

ten = tensor * tensor.T   #  逐个元素相乘
ten3 = tensor.mul(tensor)   #  逐个元素相乘
e = tensor * tensor   #  逐个元素相乘
ten1 = tensor @ tensor.T   # 矩阵相乘
# ten2 = np.matmul(tensor , tensor.T)  # 矩阵相乘
#  n = np.dot(tensor,tensor.T)   # 最多用于二维的矩阵乘法  一维点积
# n1 = tensor ** 2  #  逐个元素相乘
# n1
y = torch.rand_like(tensor)
y

np.save('result.npy',y)  # 将参数保存到磁盘 前边为文件名，后边为参数
np.load('result.npy')    # 读取文件里的数据



a = np.array([[(17,17), (21,21)], [(31,31), (41,41)]])  # shape(4,2)
b = np.array([1,1])  # shape(2)-> shape(1,2) -> shape(4,2)  [[-1,1],[-1,1],[-1,1],[-1,1]]
a + b   # 广播机制
#%%
import numpy as np

x = np.array([[1,23,3] , [33,455,6]])
y = torch.from_numpy(x)   # 转换成张量
x1 = torch.rand_like(y, dtype=torch.float)  # 创建一个跟y形状一样的张量， 范围0-1  随机
y.shape
y.dtype
x1

b = (2,5)
c = torch.rand(b)   # 正态分布创建  两行五列

c
#%%
tensor = torch.rand(3,4)  # 0-1均匀分布
tensor1 = torch.randn(3,4)  #0-1正态分布
tensor2 = torch.normal(mean =0.0,std = 1.0 ,size = (3,5))   # 离散正态分布 均值为0.0，标准差为1  形状3行5列
tensor.device  # 查看在CPU运行还是在GPU运行
tensor1

#%%
tensor = torch.ones(4, 4)
tensor[:,-1] = 0  # 将最后一列置为0
t1 = torch.cat([tensor, tensor, tensor], dim=0)  # 拼接张量，dim=0 表示按行拼接（垂直）,等于1表示按列拼接（水平）
t1


#%%
import torch
tensor = torch.arange(1,21,dtype = torch.float32).reshape(4,5)
tensor1 = torch.rand(5,5)
tensor1

tensor.device   # 查看张量在哪个硬件 CPU还是GPU
torch.cuda.is_available()   # 查看系统是否有显卡

ten = tensor.sum()   # 张量求和还是张量
print(type(ten.item()))   # 将张量转换成原始数据 float


tensor.add_(3)   # add加上下划线  表示在原张量基础上加上3  原张量更新
tensor

#%%
import torch
from torchviz import make_dot

# 定义矩阵x ，向量y ，常数a
A = torch.randn(10,10,requires_grad = True)
b = torch.randn(10,requires_grad = True)
c = torch.randn(1,requires_grad = True)
x = torch.randn(10,requires_grad = True)

result = torch.matmul(A,x.T) + torch.matmul(b,x) + c

dot = make_dot(result , params = {'A':A , "b":b , "c":c, "x":x})
dot.render('expression' , format = 'png' , cleanup = True , view = False)
