{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "data = [[1,2],[3,4]]\n",
    "x_data = torch.tensor(data)\n",
    "print(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]], dtype=torch.int32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array(data)\n",
    "print(a)\n",
    "x_np = torch.from_numpy(a)\n",
    "x_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2068, 0.7682],\n",
       "        [0.5820, 0.5667]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.rand_like(x_np,dtype=torch.float)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.3529, 0.7256, 0.4900],\n",
      "        [0.9351, 0.5110, 0.8073]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand((2,3))\n",
    "print(f\"Random Tensor: \\n {a} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m:\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64) \n",
      " n\n",
      ":tensor([[0.4151, 0.2497, 0.5916],\n",
      "        [0.8409, 0.3266, 0.7861],\n",
      "        [0.3442, 0.0475, 0.1114],\n",
      "        [0.0373, 0.2074, 0.1439],\n",
      "        [0.3618, 0.6789, 0.5779]])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "m = torch.ones(5,3,dtype=torch.double)\n",
    "n = torch.rand_like(m, dtype=torch.float)\n",
    "print(f\"m:\\n{m} \\n n\\n:{n}\")\n",
    "torch.normal(mean=.0,std=1.0,size=(5,3))\n",
    "print(torch.arange(0,10,1))\n",
    "print(torch.linspace(0,9,10,dtype=torch.int))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4])\n",
      "torch.float64\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(3,4,dtype=torch.double)\n",
    "print(tensor.shape)\n",
    "print(tensor.dtype)\n",
    "print(tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2,  3,  4],\n",
      "         [ 5,  6,  7,  8,  9],\n",
      "         [10, 11, 12, 13, 14],\n",
      "         [15, 16, 17, 18, 19]],\n",
      "\n",
      "        [[20, 21, 22, 23, 24],\n",
      "         [25, 26, 27, 28, 29],\n",
      "         [30, 31, 32, 33, 34],\n",
      "         [35, 36, 37, 38, 39]],\n",
      "\n",
      "        [[40, 41, 42, 43, 44],\n",
      "         [45, 46, 47, 48, 49],\n",
      "         [50, 51, 52, 53, 54],\n",
      "         [55, 56, 57, 58, 59]]])\n",
      "tensor([[[20, 22, 24],\n",
      "         [25, 27, 29],\n",
      "         [30, 32, 34]],\n",
      "\n",
      "        [[40, 42, 44],\n",
      "         [45, 47, 49],\n",
      "         [50, 52, 54]]])\n",
      "tensor([[[55, 56, 57, 58, 59],\n",
      "         [50, 51, 52, 53, 54],\n",
      "         [45, 46, 47, 48, 49],\n",
      "         [40, 41, 42, 43, 44]],\n",
      "\n",
      "        [[35, 36, 37, 38, 39],\n",
      "         [30, 31, 32, 33, 34],\n",
      "         [25, 26, 27, 28, 29],\n",
      "         [20, 21, 22, 23, 24]],\n",
      "\n",
      "        [[15, 16, 17, 18, 19],\n",
      "         [10, 11, 12, 13, 14],\n",
      "         [ 5,  6,  7,  8,  9],\n",
      "         [ 0,  1,  2,  3,  4]]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.arange(60).reshape(3,4,5)\n",
    "print(tensor[:,:,::])\n",
    "print(tensor[1:,:3,::2])\n",
    "print(torch.flip(tensor, dims=[0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1.])\n",
      "tensor([1., 1., 1., 1.])\n",
      "tensor([1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4,4)\n",
    "print(tensor[0])\n",
    "print(tensor[:,0])\n",
    "print(tensor[:,-1])\n",
    "tensor[:,1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "#dim参数，指定在哪个维度上进行拼接，可倒数\n",
    "tensor1 = torch.ones(4,4)\n",
    "t1 = torch.cat([tensor1,tensor1],dim=0)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 4])\n",
      "tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7]],\n",
      "\n",
      "        [[ 8,  9, 10, 11],\n",
      "         [12, 13, 14, 15]],\n",
      "\n",
      "        [[16, 17, 18, 19],\n",
      "         [20, 21, 22, 23]],\n",
      "\n",
      "        [[24, 25, 26, 27],\n",
      "         [28, 29, 30, 31]]])\n",
      "tensor([[[ 1.,  1.,  1.,  1.],\n",
      "         [ 1.,  1.,  1.,  1.],\n",
      "         [ 1.,  1.,  1.,  1.],\n",
      "         [ 1.,  1.,  1.,  1.],\n",
      "         [ 0.,  1.,  2.,  3.],\n",
      "         [ 4.,  5.,  6.,  7.]],\n",
      "\n",
      "        [[ 1.,  1.,  1.,  1.],\n",
      "         [ 1.,  1.,  1.,  1.],\n",
      "         [ 1.,  1.,  1.,  1.],\n",
      "         [ 1.,  1.,  1.,  1.],\n",
      "         [ 8.,  9., 10., 11.],\n",
      "         [12., 13., 14., 15.]],\n",
      "\n",
      "        [[ 1.,  1.,  1.,  1.],\n",
      "         [ 1.,  1.,  1.,  1.],\n",
      "         [ 1.,  1.,  1.,  1.],\n",
      "         [ 1.,  1.,  1.,  1.],\n",
      "         [16., 17., 18., 19.],\n",
      "         [20., 21., 22., 23.]],\n",
      "\n",
      "        [[ 1.,  1.,  1.,  1.],\n",
      "         [ 1.,  1.,  1.,  1.],\n",
      "         [ 1.,  1.,  1.,  1.],\n",
      "         [ 1.,  1.,  1.,  1.],\n",
      "         [24., 25., 26., 27.],\n",
      "         [28., 29., 30., 31.]]])\n"
     ]
    }
   ],
   "source": [
    "#高维张量的cat 操作，需要保证其他维度的大小一致\n",
    "tensor1 = torch.ones(4,4,4)\n",
    "t1 = torch.cat([tensor1,tensor1],dim=0)\n",
    "print(t1.shape)\n",
    "tensor2 = torch.arange(32).reshape(4,2,4)\n",
    "print(tensor2)\n",
    "t1 = torch.cat([tensor1,tensor2],dim=1)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n",
      "tensor(4.)\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bucci\\AppData\\Local\\Temp\\ipykernel_5884\\3175096295.py:12: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3701.)\n",
      "  print(torch.dot(tensor1,tensor1.T))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.ones(4,4)\n",
    "tensor[:,1] = 0\n",
    "y1 = tensor@tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "\n",
    "#out参数，指定输出的张量\n",
    "y3 = torch.rand_like(tensor)\n",
    "print(torch.matmul(tensor,tensor.T))\n",
    "\n",
    "#torch.dot()只能计算一维张量的点积\n",
    "tensor1 = torch.ones(4)\n",
    "print(torch.dot(tensor1,tensor1.T))\n",
    "\n",
    "z1 = tensor*tensor\n",
    "print(z1)\n",
    "z2 = tensor.mul(tensor)\n",
    "print(z2)\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor,tensor,out=z3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(16)\n",
      "16 <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "agg = torch.ones_like(tensor,dtype=int).sum()\n",
    "print(agg)\n",
    "agg_item = agg.item()\n",
    "print(agg_item,type(agg_item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "tensor([[6., 6., 6., 6.],\n",
      "        [6., 6., 6., 6.],\n",
      "        [6., 6., 6., 6.],\n",
      "        [6., 6., 6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4,4)\n",
    "tensor.add(5)\n",
    "print(tensor)\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "tensor([2., 2., 2., 2., 2.])\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "#numpy和tensor之间的转换，共享内存，修改一个会影响另一个\n",
    "t = torch.ones(5)\n",
    "print(t)\n",
    "n = t.numpy()\n",
    "n +=1\n",
    "print(t)\n",
    "\n",
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)\n",
    "np.add(n,1,out=n)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2795, -0.4586],\n",
      "        [-1.4240, -1.3557]], grad_fn=<AddBackward0>)\n",
      "tensor([[-0.0243, -1.3823, -0.5615],\n",
      "        [-0.9631, -1.0480, -0.5816],\n",
      "        [-0.5453, -0.9644, -0.7422]], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'dot2.pdf'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchviz import make_dot\n",
    "A = torch.randn((10,2),requires_grad=True)\n",
    "b = torch.randn((2,3),requires_grad=True)\n",
    "c = torch.randn(1,requires_grad=True)\n",
    "x = torch.randn((3,2),requires_grad=True)\n",
    "#x^T@A + b@x +c\n",
    "\n",
    "result1 = torch.matmul(A,x.T)[:2,:2] + b@x + c\n",
    "result2 = torch.matmul(A,x.T)[:3,:3] + x@b + c\n",
    "print(result1)\n",
    "print(result2)\n",
    "\n",
    "dot = make_dot(result1,params={\"A\":A,\"b\":b,\"c\":c,\"x\":x})\n",
    "dot2 = make_dot(result2,params={\"A\":A,\"b\":b,\"c\":c,\"x\":x})\n",
    "dot.render('dot')\n",
    "dot2.render('dot2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3297, -0.1304],\n",
      "        [ 0.8220,  0.3325]], grad_fn=<MmBackward0>)\n",
      "tensor([[ 0.1074, -0.1422,  0.1918],\n",
      "        [ 0.5848,  0.2608, -0.2118],\n",
      "        [-0.3034, -0.2870,  0.2940]], grad_fn=<MmBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'NEWdot2.pdf'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchviz import make_dot\n",
    "A = torch.randn((2,3),requires_grad=True)\n",
    "B = torch.randn((3,2),requires_grad=True)\n",
    "\n",
    "#x^T@A + b@x +c\n",
    "result1 = A@B\n",
    "result2 = B@A\n",
    "print(result1)\n",
    "print(result2)\n",
    "dot = make_dot(result1,params={\"A\":A,\"B\":B})\n",
    "dot2 = make_dot(result2,params={\"A\":A,\"B\":B})\n",
    "dot.render('NEWdot')\n",
    "dot2.render('NEWdot2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
